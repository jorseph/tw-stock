import pandas as pd
import logging
import os
import requests
import signal
import sys
from telegram import Update
from telegram.ext import Application, CommandHandler, MessageHandler, filters, CallbackContext
from dotenv import load_dotenv
from datetime import datetime, timedelta
import numpy as np
import asyncio
import json
import aiohttp

# è¨­å®šæ—¥èªŒ
logging.basicConfig(format="%(asctime)s - %(name)s - %(levelname)s - %(message)s", level=logging.INFO)
logger = logging.getLogger(__name__)

# å‰µå»ºä¸€å€‹å…¨å±€çš„ application è®Šé‡
app = None

# æ·»åŠ å…¨å±€è®Šé‡ä¾†è¿½è¹¤åŸ·è¡Œç‹€æ…‹
is_processing = False
current_task = None
should_cancel = False  # æ–°å¢å–æ¶ˆæ¨™è¨˜

# ä¿¡è™Ÿè™•ç†å‡½æ•¸
def signal_handler(signum, frame):
    logger.info("æ”¶åˆ°çµ‚æ­¢ä¿¡è™Ÿï¼Œæ­£åœ¨å„ªé›…é€€å‡º...")
    if app:
        logger.info("æ­£åœ¨åœæ­¢ Telegram Bot...")
        app.stop()
    sys.exit(0)

# print("ç•¶å‰å·¥ä½œç›®éŒ„:", os.getcwd())

import pandas as pd
from telegram import Update
from telegram.ext import CallbackContext

load_dotenv()
FINMIND_API_KEY = os.getenv("FINMIND_API_KEY")
FINMIND_URL = "https://api.finmindtrade.com/api/v4/data"

# è®€å–è‚¡ç¥¨åŸºæœ¬è³‡è¨Š CSV
CSV_FILE = "Calculated_Stock_Values.csv"
df = pd.read_csv(CSV_FILE)

# ç¢ºä¿ "ä»£è™Ÿ" æ¬„ä½ç‚ºå­—ä¸²
df["ä»£è™Ÿ"] = df["ä»£è™Ÿ"].astype(str)

# è®€å–é…æ¯è³‡è¨Š CSV
DIVIDEND_CSV_FILE = "all_stock_dividends.csv"
df_dividend = pd.read_csv(DIVIDEND_CSV_FILE)

# ç¢ºä¿ "stock_id" æ¬„ä½ç‚ºå­—ä¸²
df_dividend["stock_id"] = df_dividend["stock_id"].astype(str)

# ç¢ºä¿ "CashEarningsDistribution" æ¬„ä½æ˜¯æ•¸å€¼é¡å‹ï¼ˆé¿å… NaN å•é¡Œï¼‰
df_dividend["CashEarningsDistribution"] = pd.to_numeric(df_dividend["CashEarningsDistribution"], errors='coerce')

# åœ¨æ–‡ä»¶é–‹é ­æ·»åŠ ç·©å­˜ç›¸é—œè®Šé‡
CACHE_FILE = "stock_cache.json"  # æš«å­˜æª”æ¡ˆåç¨±
CACHE_DURATION = timedelta(hours=24)  # ç·©å­˜æœ‰æ•ˆæœŸç‚º 24 å°æ™‚

# å…¨å±€ç·©å­˜è®Šé‡
price_cache = {}  # è‚¡åƒ¹ç·©å­˜

def save_cache():
    """ä¿å­˜æš«å­˜è³‡æ–™"""
    try:
        logger.info("é–‹å§‹ä¿å­˜ç·©å­˜æ•¸æ“š...")
        cache_data = {
            'price_cache': price_cache
        }
        
        logger.info(f"è‚¡åƒ¹ç·©å­˜æ•¸é‡ï¼š{len(price_cache)}")
        
        logger.info(f"é–‹å§‹å¯«å…¥ç·©å­˜æ–‡ä»¶ï¼š{CACHE_FILE}")
        with open(CACHE_FILE, 'w') as f:
            json.dump(cache_data, f)
        logger.info("ç·©å­˜æ•¸æ“šä¿å­˜å®Œæˆ")
    except Exception as e:
        logger.error(f"ä¿å­˜æš«å­˜æ™‚ç™¼ç”ŸéŒ¯èª¤: {str(e)}")
        logger.error(f"éŒ¯èª¤è©³æƒ…: {type(e).__name__}")
        import traceback
        logger.error(f"éŒ¯èª¤å †ç–Š: {traceback.format_exc()}")

def load_cache():
    """è¼‰å…¥æš«å­˜è³‡æ–™"""
    try:
        if os.path.exists(CACHE_FILE):
            logger.info(f"é–‹å§‹è¼‰å…¥ç·©å­˜æ–‡ä»¶ï¼š{CACHE_FILE}")
            with open(CACHE_FILE, 'r') as f:
                cache_data = json.load(f)
                
                # æª¢æŸ¥ price_cache
                if 'price_cache' in cache_data:
                    logger.info(f"æˆåŠŸè¼‰å…¥è‚¡åƒ¹ç·©å­˜ï¼Œå…± {len(cache_data['price_cache'])} æ”¯è‚¡ç¥¨")
                    logger.info(f"å‰ 5 æ”¯è‚¡ç¥¨çš„è‚¡åƒ¹ï¼š{dict(list(cache_data['price_cache'].items())[:5])}")
                else:
                    logger.error("ç·©å­˜æ–‡ä»¶ä¸­æ²’æœ‰ price_cache æ•¸æ“š")
                
                logger.info("ç·©å­˜è¼‰å…¥å®Œæˆ")
                return cache_data.get('price_cache', {})
        else:
            logger.warning(f"ç·©å­˜æ–‡ä»¶ {CACHE_FILE} ä¸å­˜åœ¨")
    except Exception as e:
        logger.error(f"è¼‰å…¥æš«å­˜æ™‚ç™¼ç”ŸéŒ¯èª¤: {str(e)}")
        logger.error(f"éŒ¯èª¤è©³æƒ…: {type(e).__name__}")
        import traceback
        logger.error(f"éŒ¯èª¤å †ç–Š: {traceback.format_exc()}")
    return {}

# è¼‰å…¥æš«å­˜è³‡æ–™
price_cache = load_cache()

def get_cached_price(stock_id):
    """å¾ç·©å­˜ç²å–è‚¡åƒ¹"""
    global price_cache
    
    try:
        # ç¢ºä¿ç·©å­˜å·²è¼‰å…¥
        if not price_cache:
            logger.info("è‚¡åƒ¹ç·©å­˜ç‚ºç©ºï¼Œå˜—è©¦é‡æ–°è¼‰å…¥")
            price_cache = load_cache()
            
        # æª¢æŸ¥è‚¡ç¥¨æ˜¯å¦åœ¨ç·©å­˜ä¸­
        if stock_id in price_cache:
            logger.info(f"æˆåŠŸå¾ç·©å­˜ç²å–è‚¡ç¥¨ {stock_id} çš„è‚¡åƒ¹ï¼š{price_cache[stock_id]}")
            return price_cache[stock_id]
        else:
            logger.warning(f"è‚¡ç¥¨ {stock_id} ä¸åœ¨è‚¡åƒ¹ç·©å­˜ä¸­")
            logger.info(f"ç•¶å‰ç·©å­˜ä¸­çš„è‚¡ç¥¨æ•¸é‡ï¼š{len(price_cache)}")
            logger.info(f"ç·©å­˜ä¸­çš„è‚¡ç¥¨åˆ—è¡¨ï¼š{list(price_cache.keys())[:10]}...")  # åªé¡¯ç¤ºå‰10æ”¯è‚¡ç¥¨
            return None
    except Exception as e:
        logger.error(f"ç²å–ç·©å­˜è‚¡åƒ¹æ™‚ç™¼ç”ŸéŒ¯èª¤: {str(e)}")
        return None

def set_cached_price(stock_id, price):
    """è¨­ç½®è‚¡åƒ¹ç·©å­˜"""
    price_cache[stock_id] = price
    save_cache()  # ä¿å­˜åˆ°æª”æ¡ˆ

# è¨­å®šæ©Ÿå™¨äºº
async def start(update: Update, context: CallbackContext) -> None:
    await update.message.reply_text("æ­¡è¿ä½¿ç”¨è‚¡ç¥¨æŸ¥è©¢æ©Ÿå™¨äººï¼è«‹è¼¸å…¥ /stock <è‚¡ç¥¨ä»£è™Ÿ> æˆ– /recommend")


# Telegram Bot æŒ‡ä»¤ï¼š/stock_estimate 2330
async def stock_estimate(update: Update, context: CallbackContext) -> None:
    if not context.args:
        await update.message.reply_text("è«‹è¼¸å…¥è‚¡ç¥¨ä»£è™Ÿï¼Œä¾‹å¦‚ï¼š/stock_estimate 2330")
        return

    stock_id = context.args[0]
    df_result = await calculate_quarterly_stock_estimates(stock_id)

    if df_result is None:
        await update.message.reply_text(f"âš ï¸ ç„¡æ³•ç²å– {stock_id} çš„æ•¸æ“šï¼Œè«‹æª¢æŸ¥ API è¨­å®šæˆ–è‚¡ç¥¨ä»£è™Ÿ")
        return

    # å–æœ€è¿‘ 4 å­£æ•¸æ“š
    df_result = df_result.tail(4)

    # ç”Ÿæˆå›æ‡‰è¨Šæ¯
    message = f"ğŸ“Š **{stock_id} å­£åº¦ ROE & æ¨ä¼°è‚¡åƒ¹** ğŸ“Š\n"
    for _, row in df_result.iterrows():
        message += (
            f"\nğŸ“… **å­£åº¦**: {row['quarter']}"
            f"\nğŸ“Š **ROE**: {row['ROE']:.2f}%"
            f"\nğŸ¦ **BVPS**: {row['BVPS']:.2f} å…ƒ"
            f"\nğŸ’° **æ¨ä¼°EPS**: {row['æ¨ä¼°EPS']:.2f} å…ƒ"
            f"\nğŸ“ˆ **PER å€é–“**: {row['PER_æœ€ä½å€¼']:.2f} ~ {row['PER_æœ€é«˜å€¼']:.2f}"
            f"\nğŸ“‰ **ä½è‚¡åƒ¹**: {row['ä½è‚¡åƒ¹']:.2f} å…ƒ"
            f"\nğŸ“Š **æ­£å¸¸è‚¡åƒ¹**: {row['æ­£å¸¸è‚¡åƒ¹']:.2f} å…ƒ"
            f"\nğŸ“ˆ **é«˜è‚¡åƒ¹**: {row['é«˜è‚¡åƒ¹']:.2f} å…ƒ"
            f"\n--------------------"
        )

    await update.message.reply_text(message, parse_mode="Markdown")


async def etf(update: Update, context: CallbackContext) -> None:
    if not context.args:
        await update.message.reply_text("è«‹è¼¸å…¥ ETF ä»£è™Ÿï¼Œä¾‹å¦‚ï¼š/etf 00713")
        return
    
    # ğŸ”¹ æŸ¥è©¢ç•¶å‰è‚¡åƒ¹
    stock_id = context.args[0]
    current_price = await get_current_stock_price(stock_id)

    if current_price is None:
        await update.message.reply_text(f"ç„¡æ³•ç²å– {stock_id} çš„æœ€æ–°è‚¡åƒ¹ï¼Œè«‹ç¨å¾Œå†è©¦")
        return

    # ğŸ”¹ è¨ˆç®—æœ€è¿‘ä¸€å¹´é…æ¯ç¸½é¡ & æ®–åˆ©ç‡
    # total_dividends, dividend_yield = calculate_dividend_yield(stock_id, current_price)
    total_dividends, dividend_yield, dividends_count = calculate_all_dividend_yield(stock_id, current_price)

    # ğŸ”¹ å›æ‡‰è¨Šæ¯
    message = (
        f"ğŸ“Š **ETF è³‡è¨Š - {stock_id}**\n"
        f"ğŸ”¹ **ç•¶å‰è‚¡åƒ¹**: {current_price:.2f} å…ƒ\n"
        f"ğŸ’¸ **æœ€è¿‘ä¸€å¹´é…æ¯ç¸½é¡**: {total_dividends:.2f} å…ƒ ğŸ’°\n"
        f"ğŸ“Š **æ®–åˆ©ç‡**: {dividend_yield:.2f}%\n"
        f"ğŸ”¹ **é…æ¯ç­†æ•¸**: {dividends_count} ç­†\n"
    )
    
    await update.message.reply_text(message, parse_mode="Markdown")


# ä¿®æ”¹ get_current_stock_price å‡½æ•¸ç‚ºç•°æ­¥å‡½æ•¸
async def get_current_stock_price(stock_id):
    # å…ˆæª¢æŸ¥ç·©å­˜
    cached_price = get_cached_price(stock_id)
    if cached_price is not None:
        return cached_price

    # è¨­å®šæœ€å¤§å›æº¯å¤©æ•¸ï¼Œé¿å…éåº¦è«‹æ±‚ API
    max_days = 5  
    check_date = datetime.today() - timedelta(days=1)  # é è¨­æŸ¥è©¢å‰ä¸€å¤©

    for _ in range(max_days):
        # æ ¼å¼åŒ–æ—¥æœŸ
        start_date = check_date.strftime('%Y-%m-%d')

        parameter = {
            "dataset": "TaiwanStockPrice",
            "data_id": stock_id,
            "start_date": start_date,
            "token": FINMIND_API_KEY,
        }

        async with aiohttp.ClientSession() as session:
            async with session.get(FINMIND_URL, params=parameter) as response:
                data = await response.json()

                # æª¢æŸ¥ API å›æ‡‰æ˜¯å¦æœ‰æ•¸æ“š
                if "data" in data and isinstance(data["data"], list) and len(data["data"]) > 0:
                    df_price = pd.DataFrame(data["data"])
                    latest_price = df_price.sort_values(by="date", ascending=False).iloc[0]["close"]
                    # è¨­ç½®ç·©å­˜
                    set_cached_price(stock_id, latest_price)
                    return latest_price

                # å¦‚æœæ²’æœ‰æ•¸æ“šï¼Œå‘å‰æ¨ä¸€å¤©
                check_date -= timedelta(days=1)

    return None


def calculate_dividend_yield(stock_id, current_price):
    """ è¨ˆç®—è©² ETF æˆ–è‚¡ç¥¨çš„æœ€è¿‘ä¸€å¹´åº¦é…æ¯ç¸½é¡ï¼Œä¸¦è¨ˆç®—æ®–åˆ©ç‡ """
    
    # éæ¿¾ç‰¹å®šè‚¡ç¥¨
    stock_dividends = df_dividend[(df_dividend["stock_id"] == stock_id) & (df_dividend["CashEarningsDistribution"] > 0)].copy()

    # ç¢ºä¿ date æ¬„ä½æ˜¯ datetime æ ¼å¼
    stock_dividends["date"] = pd.to_datetime(stock_dividends["date"], errors="coerce")

    if stock_dividends.empty:
        return 0.0, 0.0  # å¦‚æœè©²è‚¡ç¥¨ç„¡é…æ¯è³‡æ–™ï¼Œå‰‡å›å‚³ 0

    # ğŸ”¹ å–å¾—æœ€è¿‘ä¸€å¹´çš„é…æ¯
    one_year_ago = datetime.today() - timedelta(days=365)
    
    # **é€™è¡ŒéŒ¯èª¤çš„æ¯”è¼ƒæ”¹ç‚ºç¢ºä¿ date æ¬„ä½æ˜¯ datetime**
    last_year_dividends = stock_dividends[stock_dividends["date"] >= one_year_ago]

    # è¨ˆç®—å¹´åº¦é…æ¯ç¸½é¡
    total_dividends = last_year_dividends["CashEarningsDistribution"].sum()

    # è¨ˆç®—æ®–åˆ©ç‡
    if current_price > 0:
        dividend_yield = (total_dividends / current_price) * 100
    else:
        dividend_yield = 0.0

    return total_dividends, dividend_yield


# ğŸ”¹ æŸ¥è©¢é…æ¯è³‡æ–™ä¸¦è¨ˆç®—å®Œæ•´æ®–åˆ©ç‡
def calculate_all_dividend_yield(stock_id, current_price):
    """ 
    è¨ˆç®—å®Œæ•´æ®–åˆ©ç‡ï¼ˆåŒ…å«ç¾é‡‘èˆ‡è‚¡ç¥¨è‚¡åˆ©ï¼‰ 
    """
    # ğŸ”¹ éæ¿¾è©²è‚¡ç¥¨çš„é…æ¯è³‡æ–™
    stock_dividends = df_dividend[df_dividend["stock_id"] == stock_id].copy()

    # ç¢ºä¿ date æ¬„ä½æ˜¯ datetime æ ¼å¼
    stock_dividends["date"] = pd.to_datetime(stock_dividends["date"], errors="coerce")

    if stock_dividends.empty:
        return 0.0, 0.0, 0  # å¦‚æœè©²è‚¡ç¥¨ç„¡é…æ¯è³‡æ–™ï¼Œå‰‡å›å‚³ 0

    # å…ˆæŒ‰ç…§æ—¥æœŸæ’åºï¼ˆæœ€æ–°çš„åœ¨å‰ï¼‰
    stock_dividends = stock_dividends.sort_values(by="date", ascending=False)

    # å–å¾—æœ€è¿‘ä¸€å¹´çš„é…æ¯
    one_year_ago = datetime.today() - timedelta(days=365)
    today = datetime.today()
    
    # å–å¾—æœ€è¿‘ä¸€å¹´çš„é…æ¯è³‡æ–™ï¼Œä¸¦ç¢ºä¿ä¸é‡è¤‡
    last_year_dividends = stock_dividends[
        (stock_dividends["date"] >= one_year_ago) & 
        (stock_dividends["date"] <= today) &  # æ’é™¤æœªä¾†çš„é…æ¯æ—¥æœŸ
        (stock_dividends["CashEarningsDistribution"] > 0)  # åªå–æœ‰ç¾é‡‘è‚¡åˆ©çš„è³‡æ–™
    ].drop_duplicates(subset=["date"])  # ç§»é™¤åŒä¸€å¤©çš„é‡è¤‡è³‡æ–™
    
    # ç¢ºä¿è‡³å°‘æœ‰ 1 ç­†é…æ¯è³‡æ–™
    if last_year_dividends.empty:
        return 0.0, 0.0, 0

    # è¨ˆç®—æœ€è¿‘ä¸€å¹´çš„ **ç¾é‡‘è‚¡åˆ©ç¸½é¡**
    total_cash_dividends = last_year_dividends["CashEarningsDistribution"].sum()

    # è¨ˆç®—æœ€è¿‘ä¸€å¹´çš„ **è‚¡ç¥¨è‚¡åˆ©ç¸½é¡**
    total_stock_dividends = last_year_dividends["StockEarningsDistribution"].sum()

    # **è¨ˆç®—é™¤æ¬Šæ¯å¾Œè‚¡åƒ¹**
    ex_rights_price = max(current_price - total_cash_dividends, 0)  # ç¢ºä¿è‚¡åƒ¹ä¸ç‚ºè² 

    # **è¨ˆç®—è‚¡ç¥¨è‚¡åˆ©åƒ¹å€¼**
    stock_dividend_value = total_stock_dividends * ex_rights_price / 1000

    # **è¨ˆç®—ç¸½è‚¡åˆ©åƒ¹å€¼**
    total_dividend_value = stock_dividend_value + (total_cash_dividends)

    # **è¨ˆç®—é‚„åŸæ®–åˆ©ç‡**
    if current_price > 0:
        restored_dividend_yield = (total_dividend_value / current_price) * 100.00
    else:
        restored_dividend_yield = 0.0

    return total_dividend_value, restored_dividend_yield, len(last_year_dividends)


# ä¿®æ”¹ calculate_quarterly_stock_estimates å‡½æ•¸ç‚ºç•°æ­¥å‡½æ•¸
async def calculate_quarterly_stock_estimates(stock_id, start_date="2020-01-01", end_date="2025-12-31"):
    """ é€é FinMind API å–å¾— PBRã€PERï¼Œè¨ˆç®—å­£åº¦ ROEã€BVPSã€æ¨ä¼°è‚¡åƒ¹ """
    parameter = {
        "dataset": "TaiwanStockPER",
        "data_id": stock_id,
        "start_date": start_date,
        "end_date": end_date,
        "token": FINMIND_API_KEY,
    }

    async with aiohttp.ClientSession() as session:
        async with session.get(FINMIND_URL, params=parameter) as response:
            data = await response.json()

            if "data" not in data or not isinstance(data["data"], list) or len(data["data"]) == 0:
                return None

            df = pd.DataFrame(data["data"])

            # ç¢ºä¿æ•¸æ“šæ ¼å¼
            df["date"] = pd.to_datetime(df["date"])
            df["PBR"] = pd.to_numeric(df["PBR"], errors="coerce")
            df["PER"] = pd.to_numeric(df["PER"], errors="coerce")

            # è¨ˆç®— ROE (%)
            df["ROE"] = (df["PBR"] / df["PER"]) * 100

            # ä¾å­£åº¦å–æ•¸æ“š
            df["quarter"] = df["date"].dt.to_period("Q")
            
            # è¨ˆç®—å­£åº¦ PER çµ±è¨ˆæ•¸æ“š
            df_per_stats = df.groupby("quarter")["PER"].agg([
                ("PER_æœ€é«˜å€¼", "max"),
                ("PER_å¹³å‡å€¼", "mean"),
                ("PER_æœ€ä½å€¼", "min")
            ]).reset_index()

            df_quarterly = df.groupby("quarter").last().reset_index()

            # åˆä½µ PER çµ±è¨ˆæ•¸æ“š
            df_quarterly = df_quarterly.merge(df_per_stats, on="quarter", how="left")

            # å–å¾—ç›®å‰è‚¡åƒ¹
            current_price = await get_current_stock_price(stock_id)
            if current_price is None:
                return None

            # è¨ˆç®— BVPS
            df_quarterly["prev_close"] = current_price
            df_quarterly["BVPS"] = df_quarterly["prev_close"] / df_quarterly["PBR"]

            # è¨ˆç®—æ¨ä¼°EPS
            df_quarterly["æ¨ä¼°EPS"] = (df_quarterly["ROE"] / 100) * df_quarterly["BVPS"]

            # è¨ˆç®—ä¸‰ç¨®è‚¡åƒ¹ï¼ˆé«˜ã€ä¸­ã€ä½ï¼‰
            df_quarterly["é«˜è‚¡åƒ¹"] = df_quarterly["PER_æœ€é«˜å€¼"] * df_quarterly["æ¨ä¼°EPS"]
            df_quarterly["æ­£å¸¸è‚¡åƒ¹"] = df_quarterly["PER_å¹³å‡å€¼"] * df_quarterly["æ¨ä¼°EPS"]
            df_quarterly["ä½è‚¡åƒ¹"] = df_quarterly["PER_æœ€ä½å€¼"] * df_quarterly["æ¨ä¼°EPS"]

            return df_quarterly


# æ·»åŠ ç²å–å°è‚¡ä»£è™Ÿåˆ—è¡¨çš„å‡½æ•¸
def get_taiwan_stock_list():
    """å¾ FinMind API ç²å–å°è‚¡ä»£è™Ÿåˆ—è¡¨"""
    parameter = {
        "dataset": "TaiwanStockInfo",
        "token": FINMIND_API_KEY,
    }

    try:
        response = requests.get(FINMIND_URL, params=parameter)
        data = response.json()

        if "data" not in data or not isinstance(data["data"], list):
            logger.error("ç„¡æ³•å¾ FinMind API ç²å–è‚¡ç¥¨åˆ—è¡¨")
            return []

        # è½‰æ›ç‚º DataFrame
        df_stocks = pd.DataFrame(data["data"])
        
        # ç¢ºä¿ stock_id æ¬„ä½ç‚ºå­—ä¸²
        df_stocks["stock_id"] = df_stocks["stock_id"].astype(str)
        
        # éæ¿¾æ‰éä¸Šå¸‚è‚¡ç¥¨ï¼ˆé€šå¸¸è‚¡ç¥¨ä»£ç¢¼é•·åº¦ç‚º 4 ä½ï¼‰
        df_stocks = df_stocks[df_stocks["stock_id"].str.len() == 4]
        
        # éæ¿¾æ‰ç‰¹æ®Šè‚¡ç¥¨ï¼ˆå¦‚æ¬Šè­‰ã€æœŸè²¨ç­‰ï¼‰
        df_stocks = df_stocks[~df_stocks["stock_id"].str.startswith(('0', '9'))]
        
        return df_stocks["stock_id"].tolist()
        
    except Exception as e:
        logger.error(f"ç²å–è‚¡ç¥¨åˆ—è¡¨æ™‚ç™¼ç”ŸéŒ¯èª¤: {str(e)}")
        return []

# æ·»åŠ æ–·é»çºŒå‚³ç›¸é—œè®Šé‡
progress_file = "recommend_v2_progress.json"

def save_progress(stock_list, current_index):
    """ä¿å­˜ä¸‹è¼‰é€²åº¦"""
    try:
        progress_data = {
            'stock_list': stock_list,
            'current_index': current_index,
            'timestamp': datetime.now().isoformat(),
            'total_stocks': len(stock_list)
        }
        with open(progress_file, 'w') as f:
            json.dump(progress_data, f)
        logger.info(f"å·²ä¿å­˜é€²åº¦ï¼šç•¶å‰è™•ç†åˆ°ç¬¬ {current_index} ç­†ï¼Œå…± {len(stock_list)} ç­†")
    except Exception as e:
        logger.error(f"ä¿å­˜ä¸‹è¼‰é€²åº¦æ™‚ç™¼ç”ŸéŒ¯èª¤: {str(e)}")

def load_progress():
    """è¼‰å…¥é€²åº¦"""
    try:
        if os.path.exists(progress_file):
            with open(progress_file, 'r') as f:
                data = json.load(f)
                # æª¢æŸ¥é€²åº¦æ˜¯å¦éæœŸï¼ˆè¶…é 24 å°æ™‚ï¼‰
                if datetime.fromisoformat(data['timestamp']) + timedelta(hours=24) < datetime.now():
                    logger.info("ä¸‹è¼‰é€²åº¦å·²éæœŸï¼Œå°‡é‡æ–°é–‹å§‹")
                    return None, 0
                
                # é©—è­‰æ•¸æ“šå®Œæ•´æ€§
                if 'stock_list' not in data or 'current_index' not in data or 'total_stocks' not in data:
                    logger.error("ä¸‹è¼‰é€²åº¦æª”æ¡ˆæ ¼å¼ä¸æ­£ç¢º")
                    return None, 0
                
                logger.info(f"è¼‰å…¥ä¸‹è¼‰é€²åº¦ï¼šå¾ç¬¬ {data['current_index']} ç­†é–‹å§‹ï¼Œå…± {data['total_stocks']} ç­†")
                return data['stock_list'], data['current_index']
    except Exception as e:
        logger.error(f"è¼‰å…¥ä¸‹è¼‰é€²åº¦æ™‚ç™¼ç”ŸéŒ¯èª¤: {str(e)}")
    return None, 0

# æ·»åŠ å–æ¶ˆå‘½ä»¤
async def cancel_recommend(update: Update, context: CallbackContext) -> None:
    """å–æ¶ˆæ­£åœ¨åŸ·è¡Œçš„æ¨è–¦ä»»å‹™"""
    global is_processing, should_cancel
    
    if not is_processing:
        await update.message.reply_text("ç›®å‰æ²’æœ‰æ­£åœ¨åŸ·è¡Œçš„æ¨è–¦ä»»å‹™")
        return
    
    should_cancel = True
    is_processing = False
    await update.message.reply_text("å·²ç™¼é€å–æ¶ˆæŒ‡ä»¤ï¼Œæ­£åœ¨ç­‰å¾…ä»»å‹™çµæŸ...")

# ä¿®æ”¹ recommend_v2 å‡½æ•¸
async def recommend_v2(update: Update, context: CallbackContext) -> None:
    global is_processing, should_cancel
    
    # æª¢æŸ¥æ˜¯å¦å·²ç¶“åœ¨åŸ·è¡Œ
    if is_processing:
        await update.message.reply_text("âš ï¸ å·²ç¶“æœ‰ä¸€å€‹æ¨è–¦ä»»å‹™æ­£åœ¨åŸ·è¡Œä¸­ï¼Œè«‹ç­‰å¾…å®Œæˆæˆ–ä½¿ç”¨ /cancel_recommend å–æ¶ˆ")
        return
    
    # é‡ç½®å–æ¶ˆæ¨™è¨˜
    should_cancel = False
    
    # è¨­å®šé è¨­æ¨è–¦æ•¸é‡ç‚º 5
    count = 5
    
    if context.args:
        try:
            count = int(context.args[0])
            if count <= 0:
                await update.message.reply_text("è«‹è¼¸å…¥å¤§æ–¼ 0 çš„æ•¸é‡ï¼Œä¾‹å¦‚ï¼š/recommend_v2 5")
                return
            if count > 10:
                await update.message.reply_text("æœ€å¤šåªèƒ½æ¨è–¦ 10 æª”è‚¡ç¥¨ï¼Œè«‹è¼¸å…¥å°æ–¼ç­‰æ–¼ 10 çš„æ•¸å­—")
                return
        except ValueError:
            await update.message.reply_text("è«‹è¼¸å…¥æœ‰æ•ˆçš„æ•¸å­—ï¼Œä¾‹å¦‚ï¼š/recommend_v2 5")
            return

    logger.info(f"é–‹å§‹åŸ·è¡Œ recommend_v2ï¼Œæ¨è–¦æ•¸é‡ï¼š{count}")
    
    # è¨­ç½®åŸ·è¡Œç‹€æ…‹
    is_processing = True
    current_task = asyncio.current_task()
    
    try:
        # å˜—è©¦è¼‰å…¥ä¸Šæ¬¡çš„ä¸‹è¼‰é€²åº¦
        stock_list, download_index = load_progress()
        
        # å¦‚æœæ²’æœ‰ä¸‹è¼‰é€²åº¦æˆ–é€²åº¦å·²éæœŸï¼Œé‡æ–°ç²å–è‚¡ç¥¨åˆ—è¡¨
        if not stock_list:
            stock_list = get_taiwan_stock_list()
            if not stock_list:
                await update.message.reply_text("âš ï¸ ç„¡æ³•ç²å–è‚¡ç¥¨åˆ—è¡¨ï¼Œè«‹ç¨å¾Œå†è©¦")
                return
            download_index = 0
            save_progress(stock_list, download_index)
            logger.info(f"é‡æ–°é–‹å§‹ä¸‹è¼‰ï¼šç¸½è‚¡ç¥¨æ•¸é‡ {len(stock_list)}")
        
        logger.info(f"ç¸½è‚¡ç¥¨æ•¸é‡ï¼š{len(stock_list)}ï¼Œå¾ç¬¬ {download_index} ç­†é–‹å§‹ä¸‹è¼‰")
        
        # åˆ†æ‰¹ä¸‹è¼‰è‚¡ç¥¨æ•¸æ“š
        batch_size = 100  # æ¯æ‰¹è™•ç† 100 æ”¯è‚¡ç¥¨
        for i in range(download_index, len(stock_list), batch_size):
            # æª¢æŸ¥æ˜¯å¦è¢«å–æ¶ˆ
            if should_cancel:
                logger.info("æ”¶åˆ°å–æ¶ˆæŒ‡ä»¤ï¼Œæ­£åœ¨çµæŸä»»å‹™...")
                await update.message.reply_text("âš ï¸ æ¨è–¦ä»»å‹™å·²è¢«å–æ¶ˆ")
                return
                
            batch_stocks = stock_list[i:i + batch_size]
            logger.info(f"æ­£åœ¨ä¸‹è¼‰ç¬¬ {i+1} åˆ° {min(i+batch_size, len(stock_list))} æ”¯è‚¡ç¥¨")
            
            try:
                # æª¢æŸ¥å“ªäº›è‚¡ç¥¨éœ€è¦ç²å–è‚¡åƒ¹
                uncached_stocks = [stock_id for stock_id in batch_stocks if get_cached_price(stock_id) is None]
                logger.info(f"éœ€è¦ç²å–è‚¡åƒ¹çš„è‚¡ç¥¨æ•¸é‡ï¼š{len(uncached_stocks)}")
                logger.info(f"éœ€è¦ç²å–è‚¡åƒ¹çš„è‚¡ç¥¨åˆ—è¡¨ï¼š{uncached_stocks[:5]}...")  # åªé¡¯ç¤ºå‰5æ”¯è‚¡ç¥¨
                
                if uncached_stocks:
                    # åªå°æœªç·©å­˜çš„è‚¡ç¥¨é€²è¡Œ API è«‹æ±‚
                    tasks = [get_current_stock_price(stock_id) for stock_id in uncached_stocks]
                    prices = await asyncio.gather(*tasks)
                    
                    for stock_id, price in zip(uncached_stocks, prices):
                        if price is not None:
                            set_cached_price(stock_id, price)
                            logger.info(f"æˆåŠŸç²å–ä¸¦ç·©å­˜è‚¡ç¥¨ {stock_id} çš„è‚¡åƒ¹ï¼š{price}")
                
                # æ›´æ–°ä¸‹è¼‰é€²åº¦
                next_index = i + batch_size
                if next_index >= len(stock_list):
                    next_index = len(stock_list)
                save_progress(stock_list, next_index)
                logger.info(f"å·²æ›´æ–°ä¸‹è¼‰é€²åº¦åˆ°ç¬¬ {next_index} ç­†")
                
                # å®šæœŸä¿å­˜ç·©å­˜
                save_cache()
                logger.info("å·²ä¿å­˜ç·©å­˜æ•¸æ“š")
                
            except Exception as e:
                logger.error(f"ä¸‹è¼‰æ‰¹æ¬¡æ™‚ç™¼ç”ŸéŒ¯èª¤: {str(e)}")
                logger.error(f"éŒ¯èª¤è©³æƒ…: {type(e).__name__}")
                import traceback
                logger.error(f"éŒ¯èª¤å †ç–Š: {traceback.format_exc()}")
                # ä¿å­˜ç•¶å‰ä¸‹è¼‰é€²åº¦
                save_progress(stock_list, i)
                await update.message.reply_text(f"âš ï¸ ä¸‹è¼‰éç¨‹ä¸­ç™¼ç”ŸéŒ¯èª¤ï¼Œå·²ä¿å­˜é€²åº¦ï¼Œä¸‹æ¬¡å°‡å¾ç¬¬ {i+1} æ”¯è‚¡ç¥¨ç¹¼çºŒä¸‹è¼‰")
                return
        
        # é–‹å§‹è©•ä¼°è‚¡ç¥¨
        logger.info("é–‹å§‹è©•ä¼°è‚¡ç¥¨...")
        
        # å„²å­˜æ‰€æœ‰è‚¡ç¥¨çš„è©•ä¼°çµæœ
        stock_evaluations = []
        processed_stocks = set()  # ç”¨æ–¼è¿½è¹¤å·²è™•ç†çš„è‚¡ç¥¨
        
        # åˆ†æ‰¹è©•ä¼°è‚¡ç¥¨
        for i in range(0, len(stock_list), batch_size):
            # æª¢æŸ¥æ˜¯å¦è¢«å–æ¶ˆ
            if should_cancel:
                logger.info("æ”¶åˆ°å–æ¶ˆæŒ‡ä»¤ï¼Œæ­£åœ¨çµæŸä»»å‹™...")
                await update.message.reply_text("âš ï¸ æ¨è–¦ä»»å‹™å·²è¢«å–æ¶ˆ")
                return
                
            batch_stocks = stock_list[i:i + batch_size]
            logger.info(f"æ­£åœ¨è©•ä¼°ç¬¬ {i+1} åˆ° {min(i+batch_size, len(stock_list))} æ”¯è‚¡ç¥¨")
            
            try:
                # è™•ç†è©•ä¼°çµæœ
                for stock_id in batch_stocks:
                    try:
                        # æª¢æŸ¥æ˜¯å¦å·²ç¶“è™•ç†éé€™æ”¯è‚¡ç¥¨
                        if stock_id in processed_stocks:
                            logger.info(f"è‚¡ç¥¨ {stock_id} å·²ç¶“è™•ç†éï¼Œè·³é")
                            continue
                            
                        # å¾ç·©å­˜ç²å–è‚¡åƒ¹
                        current_price = get_cached_price(stock_id)
                        
                        if current_price is None:
                            logger.info(f"è‚¡ç¥¨ {stock_id} æ²’æœ‰è‚¡åƒ¹æ•¸æ“š")
                            continue
                            
                        # ç›´æ¥è¨ˆç®—ä¼°å€¼æ•¸æ“š
                        df_result = await calculate_quarterly_stock_estimates(stock_id)
                        if df_result is None:
                            logger.info(f"è‚¡ç¥¨ {stock_id} ç„¡æ³•è¨ˆç®—ä¼°å€¼æ•¸æ“š")
                            continue
                            
                        # è¼¸å‡ºæ•¸æ“šçš„å…§å®¹
                        logger.info(f"è‚¡ç¥¨ {stock_id} çš„æ•¸æ“šï¼š")
                        logger.info(f"è‚¡åƒ¹ï¼š{current_price}")
                        logger.info(f"ä¼°å€¼æ•¸æ“šï¼š\n{df_result}")
                            
                        # å–æœ€è¿‘ 4 å­£çš„è³‡æ–™
                        last_4q = df_result.tail(4)
                        if len(last_4q) < 4:
                            logger.info(f"è‚¡ç¥¨ {stock_id} çš„å­£åº¦æ•¸æ“šä¸è¶³ 4 å­£ï¼Œåªæœ‰ {len(last_4q)} å­£")
                            continue
                            
                        # å–æœ€è¿‘ä¸€å­£çš„è³‡æ–™
                        latest_data = last_4q.iloc[-1]
                        logger.info(f"è‚¡ç¥¨ {stock_id} æœ€è¿‘ä¸€å­£æ•¸æ“šï¼š\n{latest_data}")
                        
                        # æª¢æŸ¥ ROE è¶¨å‹¢
                        roe_values = last_4q["ROE"].values
                        valid_roe_values = [x for x in roe_values if not pd.isna(x) and np.isfinite(x)]
                        logger.info(f"è‚¡ç¥¨ {stock_id} çš„ ROE å€¼ï¼š{roe_values}")
                        logger.info(f"è‚¡ç¥¨ {stock_id} çš„æœ‰æ•ˆ ROE å€¼ï¼š{valid_roe_values}")
                        
                        if len(valid_roe_values) < 4:
                            logger.info(f"è‚¡ç¥¨ {stock_id} çš„æœ‰æ•ˆ ROE æ•¸æ“šä¸è¶³ 4 å­£ï¼Œåªæœ‰ {len(valid_roe_values)} å­£")
                            continue
                            
                        # è¨ˆç®— ROE è¶¨å‹¢
                        roe_trend = np.diff(valid_roe_values)
                        roe_increasing = all(x > 0 for x in roe_trend)
                        roe_decline_ratio = (max(valid_roe_values) - min(valid_roe_values)) / max(valid_roe_values) if max(valid_roe_values) > 0 else float('inf')
                        logger.info(f"è‚¡ç¥¨ {stock_id} çš„ ROE è¶¨å‹¢ï¼š{roe_trend}")
                        logger.info(f"è‚¡ç¥¨ {stock_id} çš„ ROE æ˜¯å¦ä¸Šå‡ï¼š{roe_increasing}")
                        logger.info(f"è‚¡ç¥¨ {stock_id} çš„ ROE æ³¢å‹•ç‡ï¼š{roe_decline_ratio}")
                        
                        # æª¢æŸ¥ ROE æ˜¯å¦å¤§æ–¼ 15
                        if latest_data["ROE"] <= 15:
                            logger.info(f"è‚¡ç¥¨ {stock_id} çš„ ROE ({latest_data['ROE']}) å°æ–¼ç­‰æ–¼ 15ï¼Œä¸ç¬¦åˆæ¢ä»¶")
                            continue
                            
                        if not roe_increasing and roe_decline_ratio > 0.3:
                            logger.info(f"è‚¡ç¥¨ {stock_id} çš„ ROE è¶¨å‹¢ä¸ç¬¦åˆæ¢ä»¶")
                            continue
                            
                        price_to_low = current_price / latest_data["ä½è‚¡åƒ¹"] if latest_data["ä½è‚¡åƒ¹"] > 0 else float('inf')
                        price_to_normal = current_price / latest_data["æ­£å¸¸è‚¡åƒ¹"] if latest_data["æ­£å¸¸è‚¡åƒ¹"] > 0 else float('inf')
                        logger.info(f"è‚¡ç¥¨ {stock_id} çš„åƒ¹æ ¼æ¯”ç‡ï¼š")
                        logger.info(f"price_to_low: {price_to_low}")
                        logger.info(f"price_to_normal: {price_to_normal}")
                        
                        value_score = 0
                        
                        if current_price < latest_data["ä½è‚¡åƒ¹"]:
                            value_score += 3
                        elif current_price < latest_data["æ­£å¸¸è‚¡åƒ¹"]:
                            value_score += 2
                        elif current_price < latest_data["é«˜è‚¡åƒ¹"]:
                            value_score += 1
                            
                        if latest_data["ROE"] > 15:
                            value_score += 3
                        elif latest_data["ROE"] > 10:
                            value_score += 2
                        elif latest_data["ROE"] > 8:
                            value_score += 1
                            
                        current_per = current_price / latest_data["æ¨ä¼°EPS"] if latest_data["æ¨ä¼°EPS"] > 0 else float('inf')
                        if current_per < latest_data["PER_æœ€ä½å€¼"]:
                            value_score += 3
                        elif current_per < latest_data["PER_å¹³å‡å€¼"]:
                            value_score += 2
                        elif current_per < latest_data["PER_æœ€é«˜å€¼"]:
                            value_score += 1
                            
                        if roe_increasing:
                            value_score += 3
                        elif roe_decline_ratio < 0.1:
                            value_score += 2
                        elif roe_decline_ratio < 0.2:
                            value_score += 1
                        
                        logger.info(f"è‚¡ç¥¨ {stock_id} çš„è©•åˆ†è¨ˆç®—ï¼š")
                        logger.info(f"value_score: {value_score}")
                        logger.info(f"current_per: {current_per}")
                        
                        # æ·»åŠ åˆ°è©•ä¼°çµæœåˆ—è¡¨
                        stock_evaluations.append({
                            "stock_id": stock_id,
                            "ç›®å‰è‚¡åƒ¹": current_price,
                            "ROE": latest_data["ROE"],
                            "æ¨ä¼°EPS": latest_data["æ¨ä¼°EPS"],
                            "ä½è‚¡åƒ¹": latest_data["ä½è‚¡åƒ¹"],
                            "æ­£å¸¸è‚¡åƒ¹": latest_data["æ­£å¸¸è‚¡åƒ¹"],
                            "é«˜è‚¡åƒ¹": latest_data["é«˜è‚¡åƒ¹"],
                            "value_score": value_score,
                            "price_to_low": price_to_low,
                            "price_to_normal": price_to_normal,
                            "roe_decline_ratio": roe_decline_ratio * 100,
                            "roe_trend": "ä¸Šå‡" if roe_increasing else "ä¸‹é™"
                        })
                        
                        # è¨˜éŒ„å·²è™•ç†çš„è‚¡ç¥¨
                        processed_stocks.add(stock_id)
                        logger.info(f"æˆåŠŸè©•ä¼°è‚¡ç¥¨ {stock_id}ï¼Œåˆ†æ•¸ï¼š{value_score}")
                        
                    except Exception as e:
                        logger.error(f"è™•ç†è‚¡ç¥¨ {stock_id} æ™‚ç™¼ç”ŸéŒ¯èª¤: {str(e)}")
                        continue
                
            except Exception as e:
                logger.error(f"è©•ä¼°æ‰¹æ¬¡æ™‚ç™¼ç”ŸéŒ¯èª¤: {str(e)}")
                await update.message.reply_text("âš ï¸ è©•ä¼°éç¨‹ä¸­ç™¼ç”ŸéŒ¯èª¤")
                return
        
        logger.info(f"æˆåŠŸè©•ä¼°çš„è‚¡ç¥¨æ•¸é‡ï¼š{len(stock_evaluations)}")
        logger.info(f"å·²è™•ç†çš„è‚¡ç¥¨æ•¸é‡ï¼š{len(processed_stocks)}")
        
        if not stock_evaluations:
            await update.message.reply_text("âš ï¸ æ²’æœ‰æ‰¾åˆ°ç¬¦åˆæ¢ä»¶çš„è‚¡ç¥¨")
            return
        
        # ç¢ºä¿æ²’æœ‰é‡è¤‡çš„è‚¡ç¥¨
        unique_stocks = {stock["stock_id"]: stock for stock in stock_evaluations}.values()
        sorted_stocks = sorted(unique_stocks, 
                             key=lambda x: (-x["value_score"], x["price_to_normal"]))[:count]
        
        logger.info(f"æœ€çµ‚æ¨è–¦çš„è‚¡ç¥¨æ•¸é‡ï¼š{len(sorted_stocks)}")
        logger.info(f"æ¨è–¦çš„è‚¡ç¥¨åˆ—è¡¨ï¼š{[stock['stock_id'] for stock in sorted_stocks]}")
        
        message = f"ğŸ“Š **æ¨è–¦è‚¡ç¥¨ V2 ç‰ˆæœ¬ï¼ˆå‰ {count} åï¼‰**\n\n"
        for stock in sorted_stocks:
            message += (
                f"ğŸ”¹ **{stock['stock_id']}**\n"
                f"   ğŸ’° **ç›®å‰è‚¡åƒ¹**: {stock['ç›®å‰è‚¡åƒ¹']:.2f} å…ƒ\n"
                f"   ğŸ“Š **ROE**: {stock['ROE']:.2f}%\n"
                f"   ğŸ“Š **ROEè¶¨å‹¢**: {stock['roe_trend']}\n"
                f"   ğŸ“Š **ROEæ³¢å‹•**: {stock['roe_decline_ratio']:.2f}%\n"
                f"   ğŸ’µ **æ¨ä¼°EPS**: {stock['æ¨ä¼°EPS']:.2f}\n"
                f"   ğŸ“‰ **ä½è‚¡åƒ¹**: {stock['ä½è‚¡åƒ¹']:.2f} å…ƒ\n"
                f"   ğŸ“Š **æ­£å¸¸è‚¡åƒ¹**: {stock['æ­£å¸¸è‚¡åƒ¹']:.2f} å…ƒ\n"
                f"   ğŸ“ˆ **é«˜è‚¡åƒ¹**: {stock['é«˜è‚¡åƒ¹']:.2f} å…ƒ\n"
                f"   â­ **æŠ•è³‡åƒ¹å€¼åˆ†æ•¸**: {stock['value_score']}\n"
                "--------------------\n"
            )
        
        await update.message.reply_text(message, parse_mode="Markdown")
        
    finally:
        # é‡ç½®åŸ·è¡Œç‹€æ…‹
        is_processing = False
        should_cancel = False
        current_task = None

def main():
    global app
    load_dotenv()  # è¼‰å…¥ .env è®Šæ•¸
    
    # è®€å– Heroku ç’°å¢ƒè®Šæ•¸
    BOT_TOKEN = os.getenv("BOT_TOKEN")

    if not BOT_TOKEN:
        raise ValueError("æœªæ‰¾åˆ° BOT_TOKENï¼Œè«‹åœ¨ Heroku ç’°å¢ƒè®Šæ•¸è¨­å®š BOT_TOKEN")
    
    # è¨­ç½®ä¿¡è™Ÿè™•ç†
    signal.signal(signal.SIGTERM, signal_handler)
    signal.signal(signal.SIGINT, signal_handler)
    
    try:
        app = Application.builder().token(BOT_TOKEN).build()

        app.add_handler(CommandHandler("start", start))
        app.add_handler(CommandHandler("recommend_v2", recommend_v2))
        app.add_handler(CommandHandler("cancel_recommend", cancel_recommend))  # æ·»åŠ å–æ¶ˆå‘½ä»¤
        app.add_handler(CommandHandler("etf", etf))
        app.add_handler(CommandHandler("stock_estimate", stock_estimate))

        logger.info("Bot å·²å•Ÿå‹•ä¸¦é–‹å§‹é‹è¡Œ...")
        app.run_polling()
        
    except Exception as e:
        logger.error(f"é‹è¡Œæ™‚ç™¼ç”ŸéŒ¯èª¤: {str(e)}")
        if app:
            app.stop()
        sys.exit(1)

if __name__ == "__main__":
    main()
