import pandas as pd
import logging
import os
import requests
import signal
import sys
from telegram import Update
from telegram.ext import Application, CommandHandler, MessageHandler, filters, CallbackContext
from dotenv import load_dotenv
from datetime import datetime, timedelta
import numpy as np
import asyncio
import json
import aiohttp
import time
from typing import Dict, List, Optional
import pickle

# è¨­å®šæ—¥èªŒ
logging.basicConfig(
    format="%(asctime)s - %(name)s - %(levelname)s - %(message)s",
    level=logging.INFO,
    encoding='utf-8'  # æ·»åŠ  UTF-8 ç·¨ç¢¼
)
logger = logging.getLogger(__name__)

# å‰µå»ºä¸€å€‹å…¨å±€çš„ application è®Šé‡
app = None

# æ·»åŠ å…¨å±€è®Šé‡ä¾†è¿½è¹¤åŸ·è¡Œç‹€æ…‹
is_processing = False
current_task = None
should_cancel = False

# ç·©å­˜ç›¸é—œå¸¸é‡
CACHE_FILE = "stock_data_cache.pkl"
CACHE_EXPIRY_DAYS = 7  # æ”¹ç‚º 7 å¤©ï¼Œå› ç‚ºåŸºæœ¬é¢æ•¸æ“šè®ŠåŒ–è¼ƒæ…¢
BATCH_SIZE = 100  # å¢åŠ æ‰¹æ¬¡å¤§å°
DELAY_BETWEEN_BATCHES = 1  # æ¸›å°‘æ‰¹æ¬¡é–“å»¶é²åˆ° 30 ç§’
MAX_CONCURRENT_REQUESTS = 10  # å¢åŠ ä¸¦ç™¼è«‹æ±‚æ•¸

# ç·©å­˜æ•¸æ“šçµæ§‹
class StockDataCache:
    def __init__(self):
        self.data: Dict[str, Dict] = {}
        self.last_update: Dict[str, datetime] = {}
    
    def is_valid(self, stock_id: str) -> bool:
        if stock_id not in self.last_update:
            return False
        return (datetime.now() - self.last_update[stock_id]).days < CACHE_EXPIRY_DAYS
    
    def get(self, stock_id: str) -> Optional[Dict]:
        if self.is_valid(stock_id):
            return self.data.get(stock_id)
        return None
    
    def set(self, stock_id: str, data: Dict):
        self.data[stock_id] = data
        self.last_update[stock_id] = datetime.now()
    
    def save(self):
        with open(CACHE_FILE, 'wb') as f:
            pickle.dump(self, f)
    
    @classmethod
    def load(cls) -> 'StockDataCache':
        try:
            with open(CACHE_FILE, 'rb') as f:
                return pickle.load(f)
        except (FileNotFoundError, pickle.PickleError):
            return cls()

# å…¨å±€ç·©å­˜å°è±¡
stock_cache = StockDataCache.load()

# ä¿¡è™Ÿè™•ç†å‡½æ•¸
def signal_handler(signum, frame):
    logger.info("æ”¶åˆ°çµ‚æ­¢ä¿¡è™Ÿï¼Œæ­£åœ¨å„ªé›…é€€å‡º...")
    if app:
        logger.info("æ­£åœ¨åœæ­¢ Telegram Bot...")
        app.stop()
    sys.exit(0)

# print("ç•¶å‰å·¥ä½œç›®éŒ„:", os.getcwd())

import pandas as pd
from telegram import Update
from telegram.ext import CallbackContext

load_dotenv()
FINMIND_API_KEY = os.getenv("FINMIND_API_KEY")
FINMIND_URL = "https://api.finmindtrade.com/api/v4/data"

# è®€å–è‚¡ç¥¨åŸºæœ¬è³‡è¨Š CSV
CSV_FILE = "Calculated_Stock_Values.csv"
df = pd.read_csv(CSV_FILE)

# ç¢ºä¿ "ä»£è™Ÿ" æ¬„ä½ç‚ºå­—ä¸²
df["ä»£è™Ÿ"] = df["ä»£è™Ÿ"].astype(str)

# è®€å–é…æ¯è³‡è¨Š CSV
DIVIDEND_CSV_FILE = "all_stock_dividends.csv"
df_dividend = pd.read_csv(DIVIDEND_CSV_FILE)

# ç¢ºä¿ "stock_id" æ¬„ä½ç‚ºå­—ä¸²
df_dividend["stock_id"] = df_dividend["stock_id"].astype(str)

# ç¢ºä¿ "CashEarningsDistribution" æ¬„ä½æ˜¯æ•¸å€¼é¡å‹ï¼ˆé¿å… NaN å•é¡Œï¼‰
df_dividend["CashEarningsDistribution"] = pd.to_numeric(df_dividend["CashEarningsDistribution"], errors='coerce')

# è¨­å®šæ©Ÿå™¨äºº
async def start(update: Update, context: CallbackContext) -> None:
    await update.message.reply_text("æ­¡è¿ä½¿ç”¨è‚¡ç¥¨æŸ¥è©¢æ©Ÿå™¨äººï¼è«‹è¼¸å…¥ /stock <è‚¡ç¥¨ä»£è™Ÿ> æˆ– /recommend")


# Telegram Bot æŒ‡ä»¤ï¼š/stock_estimate 2330
async def stock_estimate(update: Update, context: CallbackContext) -> None:
    if not context.args:
        await update.message.reply_text("è«‹è¼¸å…¥è‚¡ç¥¨ä»£è™Ÿï¼Œä¾‹å¦‚ï¼š/stock_estimate 2330")
        return

    stock_id = context.args[0]
    df_result = await calculate_quarterly_stock_estimates(stock_id)

    if df_result is None:
        await update.message.reply_text(f"âš ï¸ ç„¡æ³•ç²å– {stock_id} çš„æ•¸æ“šï¼Œè«‹æª¢æŸ¥ API è¨­å®šæˆ–è‚¡ç¥¨ä»£è™Ÿ")
        return

    # å–æœ€è¿‘ 4 å­£æ•¸æ“š
    df_result = df_result.tail(4)

    # ç”Ÿæˆå›æ‡‰è¨Šæ¯
    message = f"ğŸ“Š **{stock_id} å­£åº¦ ROE & æ¨ä¼°è‚¡åƒ¹** ğŸ“Š\n"
    for _, row in df_result.iterrows():
        message += (
            f"\nğŸ“… **å­£åº¦**: {row['quarter']}"
            f"\nğŸ“Š **ROE**: {row['ROE']:.2f}%"
            f"\nğŸ¦ **BVPS**: {row['BVPS']:.2f} å…ƒ"
            f"\nğŸ’° **æ¨ä¼°EPS**: {row['æ¨ä¼°EPS']:.2f} å…ƒ"
            f"\nğŸ“ˆ **PER å€é–“**: {row['PER_æœ€ä½å€¼']:.2f} ~ {row['PER_æœ€é«˜å€¼']:.2f}"
            f"\nğŸ“‰ **ä½è‚¡åƒ¹**: {row['ä½è‚¡åƒ¹']:.2f} å…ƒ"
            f"\nğŸ“Š **æ­£å¸¸è‚¡åƒ¹**: {row['æ­£å¸¸è‚¡åƒ¹']:.2f} å…ƒ"
            f"\nğŸ“ˆ **é«˜è‚¡åƒ¹**: {row['é«˜è‚¡åƒ¹']:.2f} å…ƒ"
            f"\n--------------------"
        )

    await update.message.reply_text(message, parse_mode="Markdown")


async def etf(update: Update, context: CallbackContext) -> None:
    if not context.args:
        await update.message.reply_text("è«‹è¼¸å…¥ ETF ä»£è™Ÿï¼Œä¾‹å¦‚ï¼š/etf 00713")
        return
    
    # ğŸ”¹ æŸ¥è©¢ç•¶å‰è‚¡åƒ¹
    stock_id = context.args[0]
    current_price = await get_current_stock_price(stock_id)

    if current_price is None:
        await update.message.reply_text(f"ç„¡æ³•ç²å– {stock_id} çš„æœ€æ–°è‚¡åƒ¹ï¼Œè«‹ç¨å¾Œå†è©¦")
        return

    # ğŸ”¹ è¨ˆç®—æœ€è¿‘ä¸€å¹´é…æ¯ç¸½é¡ & æ®–åˆ©ç‡
    # total_dividends, dividend_yield = calculate_dividend_yield(stock_id, current_price)
    total_dividends, dividend_yield, dividends_count = calculate_all_dividend_yield(stock_id, current_price)

    # ğŸ”¹ å›æ‡‰è¨Šæ¯
    message = (
        f"ğŸ“Š **ETF è³‡è¨Š - {stock_id}**\n"
        f"ğŸ”¹ **ç•¶å‰è‚¡åƒ¹**: {current_price:.2f} å…ƒ\n"
        f"ğŸ’¸ **æœ€è¿‘ä¸€å¹´é…æ¯ç¸½é¡**: {total_dividends:.2f} å…ƒ ğŸ’°\n"
        f"ğŸ“Š **æ®–åˆ©ç‡**: {dividend_yield:.2f}%\n"
        f"ğŸ”¹ **é…æ¯ç­†æ•¸**: {dividends_count} ç­†\n"
    )
    
    await update.message.reply_text(message, parse_mode="Markdown")


# ä¿®æ”¹ get_current_stock_price å‡½æ•¸ç‚ºç•°æ­¥å‡½æ•¸
async def get_current_stock_price(stock_id):
    """è·å–è‚¡ç¥¨å½“å‰ä»·æ ¼ï¼Œç›´æ¥ä» API è·å–æœ€è¿‘5å¤©çš„æ•°æ®"""
    try:
        # è·å–æœ€è¿‘5å¤©çš„æ•°æ®
        parameter = {
            "dataset": "TaiwanStockPrice",
            "start_date": (datetime.today() - timedelta(days=5)).strftime('%Y-%m-%d'),
            "token": FINMIND_API_KEY,
        }

        async with aiohttp.ClientSession() as session:
            async with session.get(FINMIND_URL, params=parameter) as response:
                if response.status != 200:
                    logger.error(f"API è¯·æ±‚å¤±è´¥ï¼ŒçŠ¶æ€ç ï¼š{response.status}")
                    return None

                data = await response.json()

                # æ£€æŸ¥ API å›åº”æ˜¯å¦æœ‰æ•°æ®
                if "data" in data and isinstance(data["data"], list) and len(data["data"]) > 0:
                    df_price = pd.DataFrame(data["data"])
                    
                    # ç¡®ä¿æ—¥æœŸæ ¼å¼æ­£ç¡®
                    df_price['date'] = pd.to_datetime(df_price['date'])
                    
                    # ç¡®ä¿æ•°å€¼å­—æ®µä¸ºæ•°å€¼ç±»å‹
                    numeric_columns = ['Trading_Volume', 'Trading_money', 'open', 'max', 'min', 'close', 'spread', 'Trading_turnover']
                    for col in numeric_columns:
                        if col in df_price.columns:
                            df_price[col] = pd.to_numeric(df_price[col], errors='coerce')
                    
                    # è·å–æŒ‡å®šè‚¡ç¥¨çš„æœ€æ–°æ”¶ç›˜ä»·
                    stock_data = df_price[df_price['stock_id'] == stock_id]
                    if not stock_data.empty:
                        latest_price = stock_data.sort_values('date').iloc[-1]['close']
                        logger.info(f"æˆåŠŸè·å–è‚¡ç¥¨ {stock_id} çš„æœ€æ–°ä»·æ ¼ï¼š{latest_price}")
                        return latest_price
                    else:
                        logger.warning(f"æœªæ‰¾åˆ°è‚¡ç¥¨ {stock_id} çš„ä»·æ ¼æ•°æ®")
                else:
                    logger.warning("API è¿”å›æ•°æ®ä¸ºç©º")

        return None

    except Exception as e:
        logger.error(f"è·å–è‚¡ç¥¨ {stock_id} ä»·æ ¼æ—¶å‘ç”Ÿé”™è¯¯: {str(e)}")
        return None


def calculate_dividend_yield(stock_id, current_price):
    """ è¨ˆç®—è©² ETF æˆ–è‚¡ç¥¨çš„æœ€è¿‘ä¸€å¹´åº¦é…æ¯ç¸½é¡ï¼Œä¸¦è¨ˆç®—æ®–åˆ©ç‡ """
    
    # éæ¿¾ç‰¹å®šè‚¡ç¥¨
    stock_dividends = df_dividend[(df_dividend["stock_id"] == stock_id) & (df_dividend["CashEarningsDistribution"] > 0)].copy()

    # ç¢ºä¿ date æ¬„ä½æ˜¯ datetime æ ¼å¼
    stock_dividends["date"] = pd.to_datetime(stock_dividends["date"], errors="coerce")

    if stock_dividends.empty:
        return 0.0, 0.0  # å¦‚æœè©²è‚¡ç¥¨ç„¡é…æ¯è³‡æ–™ï¼Œå‰‡å›å‚³ 0

    # ğŸ”¹ å–å¾—æœ€è¿‘ä¸€å¹´çš„é…æ¯
    one_year_ago = datetime.today() - timedelta(days=365)
    
    # **é€™è¡ŒéŒ¯èª¤çš„æ¯”è¼ƒæ”¹ç‚ºç¢ºä¿ date æ¬„ä½æ˜¯ datetime**
    last_year_dividends = stock_dividends[stock_dividends["date"] >= one_year_ago]

    # è¨ˆç®—å¹´åº¦é…æ¯ç¸½é¡
    total_dividends = last_year_dividends["CashEarningsDistribution"].sum()

    # è¨ˆç®—æ®–åˆ©ç‡
    if current_price > 0:
        dividend_yield = (total_dividends / current_price) * 100
    else:
        dividend_yield = 0.0

    return total_dividends, dividend_yield


# ğŸ”¹ æŸ¥è©¢é…æ¯è³‡æ–™ä¸¦è¨ˆç®—å®Œæ•´æ®–åˆ©ç‡
def calculate_all_dividend_yield(stock_id, current_price):
    """ 
    è¨ˆç®—å®Œæ•´æ®–åˆ©ç‡ï¼ˆåŒ…å«ç¾é‡‘èˆ‡è‚¡ç¥¨è‚¡åˆ©ï¼‰ 
    """
    # ğŸ”¹ éæ¿¾è©²è‚¡ç¥¨çš„é…æ¯è³‡æ–™
    stock_dividends = df_dividend[df_dividend["stock_id"] == stock_id].copy()

    # ç¢ºä¿ date æ¬„ä½æ˜¯ datetime æ ¼å¼
    stock_dividends["date"] = pd.to_datetime(stock_dividends["date"], errors="coerce")

    if stock_dividends.empty:
        return 0.0, 0.0, 0  # å¦‚æœè©²è‚¡ç¥¨ç„¡é…æ¯è³‡æ–™ï¼Œå‰‡å›å‚³ 0

    # å…ˆæŒ‰ç…§æ—¥æœŸæ’åºï¼ˆæœ€æ–°çš„åœ¨å‰ï¼‰
    stock_dividends = stock_dividends.sort_values(by="date", ascending=False)

    # å–å¾—æœ€è¿‘ä¸€å¹´çš„é…æ¯
    one_year_ago = datetime.today() - timedelta(days=365)
    today = datetime.today()
    
    # å–å¾—æœ€è¿‘ä¸€å¹´çš„é…æ¯è³‡æ–™ï¼Œä¸¦ç¢ºä¿ä¸é‡è¤‡
    last_year_dividends = stock_dividends[
        (stock_dividends["date"] >= one_year_ago) & 
        (stock_dividends["date"] <= today) &  # æ’é™¤æœªä¾†çš„é…æ¯æ—¥æœŸ
        (stock_dividends["CashEarningsDistribution"] > 0)  # åªå–æœ‰ç¾é‡‘è‚¡åˆ©çš„è³‡æ–™
    ].drop_duplicates(subset=["date"])  # ç§»é™¤åŒä¸€å¤©çš„é‡è¤‡è³‡æ–™
    
    # ç¢ºä¿è‡³å°‘æœ‰ 1 ç­†é…æ¯è³‡æ–™
    if last_year_dividends.empty:
        return 0.0, 0.0, 0

    # è¨ˆç®—æœ€è¿‘ä¸€å¹´çš„ **ç¾é‡‘è‚¡åˆ©ç¸½é¡**
    total_cash_dividends = last_year_dividends["CashEarningsDistribution"].sum()

    # è¨ˆç®—æœ€è¿‘ä¸€å¹´çš„ **è‚¡ç¥¨è‚¡åˆ©ç¸½é¡**
    total_stock_dividends = last_year_dividends["StockEarningsDistribution"].sum()

    # **è¨ˆç®—é™¤æ¬Šæ¯å¾Œè‚¡åƒ¹**
    ex_rights_price = max(current_price - total_cash_dividends, 0)  # ç¢ºä¿è‚¡åƒ¹ä¸ç‚ºè² 

    # **è¨ˆç®—è‚¡ç¥¨è‚¡åˆ©åƒ¹å€¼**
    stock_dividend_value = total_stock_dividends * ex_rights_price / 1000

    # **è¨ˆç®—ç¸½è‚¡åˆ©åƒ¹å€¼**
    total_dividend_value = stock_dividend_value + (total_cash_dividends)

    # **è¨ˆç®—é‚„åŸæ®–åˆ©ç‡**
    if current_price > 0:
        restored_dividend_yield = (total_dividend_value / current_price) * 100.00
    else:
        restored_dividend_yield = 0.0

    return total_dividend_value, restored_dividend_yield, len(last_year_dividends)


# ä¿®æ”¹ calculate_quarterly_stock_estimates å‡½æ•¸ç‚ºç•°æ­¥å‡½æ•¸
async def calculate_quarterly_stock_estimates(stock_id, start_date="2020-01-01", end_date=None):
    """ é€é FinMind API å–å¾— PBRã€PERï¼Œè¨ˆç®—å­£åº¦ ROEã€BVPSã€æ¨ä¼°è‚¡åƒ¹ """
    if end_date is None:
        end_date = datetime.now().strftime('%Y-%m-%d')
        
    parameter = {
        "dataset": "TaiwanStockPER",
        "data_id": stock_id,
        "start_date": start_date,
        "end_date": end_date,
        "token": FINMIND_API_KEY,
    }

    try:
        async with aiohttp.ClientSession() as session:
            async with session.get(FINMIND_URL, params=parameter) as response:
                if response.status != 200:
                    logger.error(f"API è«‹æ±‚å¤±æ•—ï¼Œç‹€æ…‹ç¢¼ï¼š{response.status}")
                    return None

                data = await response.json()
                if "data" not in data or not isinstance(data["data"], list) or len(data["data"]) == 0:
                    return None

                df = pd.DataFrame(data["data"])

                # ç¢ºä¿æ•¸æ“šæ ¼å¼
                df["date"] = pd.to_datetime(df["date"])
                df["PBR"] = pd.to_numeric(df["PBR"], errors="coerce")
                df["PER"] = pd.to_numeric(df["PER"], errors="coerce")

                # è¨ˆç®— ROE (%)
                df["ROE"] = (df["PBR"] / df["PER"]) * 100

                # ä¾å­£åº¦å–æ•¸æ“š
                df["quarter"] = df["date"].dt.to_period("Q")
                
                # è¨ˆç®—å­£åº¦ PER çµ±è¨ˆæ•¸æ“š
                df_per_stats = df.groupby("quarter")["PER"].agg([
                    ("PER_æœ€é«˜å€¼", "max"),
                    ("PER_å¹³å‡å€¼", "mean"),
                    ("PER_æœ€ä½å€¼", "min")
                ]).reset_index()

                df_quarterly = df.groupby("quarter").last().reset_index()

                # åˆä½µ PER çµ±è¨ˆæ•¸æ“š
                df_quarterly = df_quarterly.merge(df_per_stats, on="quarter", how="left")

                # å–å¾—ç›®å‰è‚¡åƒ¹
                current_price = await get_current_stock_price(stock_id)
                if current_price is None:
                    return None

                # è¨ˆç®— BVPS
                df_quarterly["prev_close"] = current_price
                df_quarterly["BVPS"] = df_quarterly["prev_close"] / df_quarterly["PBR"]

                # è¨ˆç®—æ¨ä¼°EPS
                df_quarterly["æ¨ä¼°EPS"] = (df_quarterly["ROE"] / 100) * df_quarterly["BVPS"]

                # è¨ˆç®—ä¸‰ç¨®è‚¡åƒ¹ï¼ˆé«˜ã€ä¸­ã€ä½ï¼‰
                df_quarterly["é«˜è‚¡åƒ¹"] = df_quarterly["PER_æœ€é«˜å€¼"] * df_quarterly["æ¨ä¼°EPS"]
                df_quarterly["æ­£å¸¸è‚¡åƒ¹"] = df_quarterly["PER_å¹³å‡å€¼"] * df_quarterly["æ¨ä¼°EPS"]
                df_quarterly["ä½è‚¡åƒ¹"] = df_quarterly["PER_æœ€ä½å€¼"] * df_quarterly["æ¨ä¼°EPS"]

                return df_quarterly

    except Exception as e:
        logger.error(f"ç²å–è‚¡ç¥¨ {stock_id} æ•¸æ“šæ™‚ç™¼ç”ŸéŒ¯èª¤: {str(e)}")
        return None


# æ·»åŠ ç²å–å°è‚¡ä»£è™Ÿåˆ—è¡¨çš„å‡½æ•¸
def get_taiwan_stock_list():
    """å¾ FinMind API ç²å–å°è‚¡ä»£è™Ÿåˆ—è¡¨"""
    parameter = {
        "dataset": "TaiwanStockInfo",
        "token": FINMIND_API_KEY,
    }

    try:
        response = requests.get(FINMIND_URL, params=parameter)
        data = response.json()

        if "data" not in data or not isinstance(data["data"], list):
            logger.error("ç„¡æ³•å¾ FinMind API ç²å–è‚¡ç¥¨åˆ—è¡¨")
            return []

        # è½‰æ›ç‚º DataFrame
        df_stocks = pd.DataFrame(data["data"])
        
        # ç¢ºä¿ stock_id æ¬„ä½ç‚ºå­—ä¸²
        df_stocks["stock_id"] = df_stocks["stock_id"].astype(str)
        
        # éæ¿¾æ‰éä¸Šå¸‚è‚¡ç¥¨ï¼ˆé€šå¸¸è‚¡ç¥¨ä»£ç¢¼é•·åº¦ç‚º 4 ä½ï¼‰
        df_stocks = df_stocks[df_stocks["stock_id"].str.len() == 4]
        
        # éæ¿¾æ‰ç‰¹æ®Šè‚¡ç¥¨ï¼ˆå¦‚æ¬Šè­‰ã€æœŸè²¨ç­‰ï¼‰
        df_stocks = df_stocks[~df_stocks["stock_id"].str.startswith(('0', '9'))]
        
        # æ·»åŠ æ—¥èªŒè¨˜éŒ„
        logger.info(f"å¾ API ç²å–çš„è‚¡ç¥¨ç¸½æ•¸ï¼š{len(df_stocks)}")
        logger.info(f"è‚¡ç¥¨ä»£ç¢¼ç¯„åœï¼š{df_stocks['stock_id'].min()} åˆ° {df_stocks['stock_id'].max()}")
        
        stock_list = df_stocks["stock_id"].tolist()
        logger.info(f"æˆåŠŸç²å– {len(stock_list)} æ”¯ä¸Šå¸‚è‚¡ç¥¨")
        return stock_list
        
    except Exception as e:
        logger.error(f"ç²å–è‚¡ç¥¨åˆ—è¡¨æ™‚ç™¼ç”ŸéŒ¯èª¤: {str(e)}")
        return []

# æ·»åŠ æ–·é»çºŒå‚³ç›¸é—œè®Šé‡
progress_file = "recommend_v2_progress.json"

def save_progress(stock_list, current_index):
    """ä¿å­˜ä¸‹è¼‰é€²åº¦"""
    try:
        progress_data = {
            'stock_list': stock_list,
            'current_index': current_index,
            'timestamp': datetime.now().isoformat(),
            'total_stocks': len(stock_list)
        }
        with open(progress_file, 'w') as f:
            json.dump(progress_data, f)
        logger.info(f"å·²ä¿å­˜é€²åº¦ï¼šç•¶å‰è™•ç†åˆ°ç¬¬ {current_index} ç­†ï¼Œå…± {len(stock_list)} ç­†")
    except Exception as e:
        logger.error(f"ä¿å­˜ä¸‹è¼‰é€²åº¦æ™‚ç™¼ç”ŸéŒ¯èª¤: {str(e)}")

def load_progress():
    """è¼‰å…¥é€²åº¦"""
    try:
        if os.path.exists(progress_file):
            with open(progress_file, 'r') as f:
                data = json.load(f)
                # æª¢æŸ¥é€²åº¦æ˜¯å¦éæœŸï¼ˆè¶…é 24 å°æ™‚ï¼‰
                if datetime.fromisoformat(data['timestamp']) + timedelta(hours=24) < datetime.now():
                    logger.info("ä¸‹è¼‰é€²åº¦å·²éæœŸï¼Œå°‡é‡æ–°é–‹å§‹")
                    return None, 0
                
                # é©—è­‰æ•¸æ“šå®Œæ•´æ€§
                if 'stock_list' not in data or 'current_index' not in data or 'total_stocks' not in data:
                    logger.error("ä¸‹è¼‰é€²åº¦æª”æ¡ˆæ ¼å¼ä¸æ­£ç¢º")
                    return None, 0
                
                logger.info(f"è¼‰å…¥ä¸‹è¼‰é€²åº¦ï¼šå¾ç¬¬ {data['current_index']} ç­†é–‹å§‹ï¼Œå…± {data['total_stocks']} ç­†")
                return data['stock_list'], data['current_index']
    except Exception as e:
        logger.error(f"è¼‰å…¥ä¸‹è¼‰é€²åº¦æ™‚ç™¼ç”ŸéŒ¯èª¤: {str(e)}")
    return None, 0

# æ·»åŠ å–æ¶ˆå‘½ä»¤
async def cancel_recommend(update: Update, context: CallbackContext) -> None:
    """å–æ¶ˆæ­£åœ¨åŸ·è¡Œçš„æ¨è–¦ä»»å‹™"""
    global is_processing, should_cancel
    
    if not is_processing:
        await update.message.reply_text("ç›®å‰æ²’æœ‰æ­£åœ¨åŸ·è¡Œçš„æ¨è–¦ä»»å‹™")
        return
    
    should_cancel = True
    is_processing = False
    await update.message.reply_text("å·²ç™¼é€å–æ¶ˆæŒ‡ä»¤ï¼Œæ­£åœ¨ç­‰å¾…ä»»å‹™çµæŸ...")

async def process_stock_batch(stock_ids: List[str], session: aiohttp.ClientSession) -> List[Dict]:
    """è™•ç†ä¸€æ‰¹è‚¡ç¥¨æ•¸æ“š"""
    results = []
    semaphore = asyncio.Semaphore(MAX_CONCURRENT_REQUESTS)
    
    async def process_single_stock(stock_id: str) -> Optional[Dict]:
        async with semaphore:
            try:
                # æª¢æŸ¥ç·©å­˜
                cached_data = stock_cache.get(stock_id)
                if cached_data:
                    logger.info(f"ä½¿ç”¨ç·©å­˜æ•¸æ“š: {stock_id}")
                    return cached_data
                
                # ç²å–ç•¶å‰åƒ¹æ ¼
                current_price = await get_current_stock_price(stock_id)
                if current_price is None:
                    return None
                
                # ç²å–ä¼°å€¼è³‡æ–™ï¼ˆä½¿ç”¨æ›´é•·çš„æ™‚é–“ç¯„åœï¼‰
                df_result = await calculate_quarterly_stock_estimates(stock_id, start_date="2020-01-01")
                if df_result is None or df_result.empty:
                    return None
                
                # æª¢æŸ¥æ˜¯å¦æœ‰è¶³å¤ çš„å­£åº¦è³‡æ–™
                if len(df_result) < 4:
                    return None
                
                # æª¢æŸ¥ ROE æ˜¯å¦å¤§æ–¼ 15
                latest_roe = df_result.iloc[0]["ROE"]
                if latest_roe <= 15:
                    return None
                
                # è¨ˆç®— ROE è¶¨å‹¢
                roe_values = df_result["ROE"].tolist()
                valid_roe_values = [roe for roe in roe_values if roe > 0]
                if len(valid_roe_values) < 4:
                    return None
                
                roe_trend = all(valid_roe_values[i] >= valid_roe_values[i+1] for i in range(len(valid_roe_values)-1))
                roe_volatility = (max(valid_roe_values) - min(valid_roe_values)) / min(valid_roe_values) * 100
                
                if not roe_trend and roe_volatility > 30:
                    return None
                
                # è¨ˆç®—åƒ¹å€¼åˆ†æ•¸
                price_to_low = current_price / df_result.iloc[0]["PER_æœ€ä½å€¼"]
                current_per = df_result.iloc[0]["PER_æœ€ä½å€¼"]
                value_score = (price_to_low * 0.7 + (1 / current_per) * 0.3) * 100
                
                result = {
                    "stock_id": stock_id,
                    "current_price": current_price,
                    "value_score": value_score,
                    "roe": latest_roe,
                    "price_to_low": price_to_low,
                    "current_per": current_per
                }
                
                # ä¿å­˜åˆ°ç·©å­˜
                stock_cache.set(stock_id, result)
                return result
                
            except Exception as e:
                logger.error(f"è™•ç†è‚¡ç¥¨ {stock_id} æ™‚ç™¼ç”ŸéŒ¯èª¤: {str(e)}")
                return None
    
    # ä¸¦ç™¼è™•ç†è©²æ‰¹æ¬¡çš„æ‰€æœ‰è‚¡ç¥¨
    tasks = [process_single_stock(stock_id) for stock_id in stock_ids]
    results = await asyncio.gather(*tasks)
    
    # éæ¿¾æ‰ None çµæœ
    return [r for r in results if r is not None]

async def recommend_v2(update: Update, context: CallbackContext) -> None:
    """æ¨è–¦è‚¡ç¥¨ v2 ç‰ˆæœ¬"""
    global is_processing, should_cancel
    
    if is_processing:
        await update.message.reply_text("å·²æœ‰æ¨è–¦ä»»å‹™æ­£åœ¨åŸ·è¡Œä¸­ï¼Œè«‹ç¨å¾Œå†è©¦")
        return
    
    try:
        is_processing = True
        should_cancel = False
        
        # ç²å–æ‰€æœ‰è‚¡ç¥¨ä»£ç¢¼
        parameter = {
            "dataset": "TaiwanStockPrice",
            "start_date": (datetime.today() - timedelta(days=5)).strftime('%Y-%m-%d'),
            "token": FINMIND_API_KEY,
        }

        async with aiohttp.ClientSession() as session:
            async with session.get(FINMIND_URL, params=parameter) as response:
                if response.status != 200:
                    await update.message.reply_text("ç„¡æ³•ç²å–è‚¡ç¥¨æ•¸æ“šï¼Œè«‹ç¨å¾Œå†è©¦")
                    return

                data = await response.json()
                if "data" not in data or not isinstance(data["data"], list) or len(data["data"]) == 0:
                    await update.message.reply_text("API è¿”å›æ•¸æ“šç‚ºç©º")
                    return

                # åªä¿ç•™éœ€è¦çš„å­—æ®µ
                price_data = []
                for item in data["data"]:
                    price_data.append({
                        "stock_id": item["stock_id"],
                        "date": item["date"],
                        "close": float(item["close"])
                    })
                
                df_price = pd.DataFrame(price_data)
                stock_list = df_price['stock_id'].unique().tolist()
                logger.info(f"æˆåŠŸç²å– {len(stock_list)} æ”¯è‚¡ç¥¨æ•¸æ“š")

        # åˆ†æ‰¹è™•ç†è‚¡ç¥¨
        all_results = []
        total_batches = (len(stock_list) + BATCH_SIZE - 1) // BATCH_SIZE
        
        for i in range(0, len(stock_list), BATCH_SIZE):
            if should_cancel:
                await update.message.reply_text("ä»»å‹™å·²å–æ¶ˆ")
                break
                
            batch = stock_list[i:i + BATCH_SIZE]
            current_batch = (i // BATCH_SIZE) + 1
            
            # ç™¼é€é€²åº¦æ›´æ–°
            progress_message = f"æ­£åœ¨è™•ç†ç¬¬ {current_batch}/{total_batches} æ‰¹ï¼Œå…± {len(batch)} æ”¯è‚¡ç¥¨..."
            await update.message.reply_text(progress_message)
            
            # è™•ç†ç•¶å‰æ‰¹æ¬¡
            batch_results = await process_stock_batch(batch, session)
            all_results.extend(batch_results)
            
            # æ‰¹æ¬¡é–“å»¶é²
            if current_batch < total_batches:
                await asyncio.sleep(DELAY_BETWEEN_BATCHES)
        
        # ä¿å­˜ç·©å­˜
        stock_cache.save()
        
        # æ ¹æ“šåƒ¹å€¼åˆ†æ•¸æ’åº
        all_results.sort(key=lambda x: x["value_score"], reverse=True)
        
        # é¸å–å‰ 10 æ”¯è‚¡ç¥¨
        top_10 = all_results[:10]
        
        # ç”Ÿæˆæ¨è–¦è¨Šæ¯
        message = "ğŸ“Š è‚¡ç¥¨æ¨è–¦ (v2)\n\n"
        message += "ğŸ”¹ æ ¹æ“šåƒ¹å€¼åˆ†æ•¸æ’åºï¼š\n"
        for i, stock in enumerate(top_10, 1):
            message += f"{i}. {stock['stock_id']}\n"
            message += f"   ç¾åƒ¹: {stock['current_price']:.2f}\n"
            message += f"   åƒ¹å€¼åˆ†æ•¸: {stock['value_score']:.2f}\n"
            message += f"   ROE: {stock['roe']:.2f}%\n"
            message += f"   è‚¡åƒ¹/ä½é»: {stock['price_to_low']:.2f}\n"
            message += f"   æœ¬ç›Šæ¯”: {stock['current_per']:.2f}\n\n"
        
        # æ ¹æ“š ROE æ’åº
        roe_sorted = sorted(all_results, key=lambda x: x["roe"], reverse=True)
        top_10_roe = roe_sorted[:10]
        
        message += "\nğŸ”¹ æ ¹æ“š ROE æ’åºï¼š\n"
        for i, stock in enumerate(top_10_roe, 1):
            message += f"{i}. {stock['stock_id']}\n"
            message += f"   ç¾åƒ¹: {stock['current_price']:.2f}\n"
            message += f"   ROE: {stock['roe']:.2f}%\n"
            message += f"   åƒ¹å€¼åˆ†æ•¸: {stock['value_score']:.2f}\n"
            message += f"   è‚¡åƒ¹/ä½é»: {stock['price_to_low']:.2f}\n"
            message += f"   æœ¬ç›Šæ¯”: {stock['current_per']:.2f}\n\n"
        
        await update.message.reply_text(message)
        
    except Exception as e:
        logger.error(f"æ¨è–¦è‚¡ç¥¨æ™‚ç™¼ç”ŸéŒ¯èª¤: {str(e)}")
        await update.message.reply_text("è™•ç†éç¨‹ä¸­ç™¼ç”ŸéŒ¯èª¤ï¼Œè«‹ç¨å¾Œå†è©¦")
    finally:
        is_processing = False

def main():
    global app
    load_dotenv()  # è¼‰å…¥ .env è®Šæ•¸
    
    # è®€å– Heroku ç’°å¢ƒè®Šæ•¸
    BOT_TOKEN = os.getenv("BOT_TOKEN")

    if not BOT_TOKEN:
        raise ValueError("æœªæ‰¾åˆ° BOT_TOKENï¼Œè«‹åœ¨ Heroku ç’°å¢ƒè®Šæ•¸è¨­å®š BOT_TOKEN")
    
    # è¨­ç½®ä¿¡è™Ÿè™•ç†
    signal.signal(signal.SIGTERM, signal_handler)
    signal.signal(signal.SIGINT, signal_handler)
    
    try:
        app = Application.builder().token(BOT_TOKEN).build()

        app.add_handler(CommandHandler("start", start))
        app.add_handler(CommandHandler("recommend_v2", recommend_v2))
        app.add_handler(CommandHandler("cancel_recommend", cancel_recommend))  # æ·»åŠ å–æ¶ˆå‘½ä»¤
        app.add_handler(CommandHandler("etf", etf))
        app.add_handler(CommandHandler("stock_estimate", stock_estimate))

        logger.info("Bot å·²å•Ÿå‹•ä¸¦é–‹å§‹é‹è¡Œ...")
        app.run_polling()
        
    except Exception as e:
        logger.error(f"é‹è¡Œæ™‚ç™¼ç”ŸéŒ¯èª¤: {str(e)}")
        if app:
            app.stop()
        sys.exit(1)

if __name__ == "__main__":
    main()
